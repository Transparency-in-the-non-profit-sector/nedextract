{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nedextract use case example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we will analyse a pdf file using all the different options that nedextract offers. As a test case we will be looking at the fictive annual report './Data/Jaarverslag_Bedrijf.pdf'.\n",
    "The file fulfills the following requirements:\n",
    "\n",
    "- the file is machine readable (does not have to be analysed using OCR)\n",
    "- the file is written in Dutch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lootes/miniconda3/envs/tnps/lib/python3.11/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "# Load the requirements\n",
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from os.path import exists\n",
    "from nedextract import run_nedextract\n",
    "from nedextract import classify_organisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the example data file or replace the file name with your own\n",
    "file = 'Data/Jaarverslag_Bedrijf.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the file exists\n",
    "exists(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function run in module nedextract.run_nedextract:\n",
      "\n",
      "run(directory=None, file=None, url=None, urlf=None, tasks=['people'], anbis=None, model=None, labels=None, vectors=None, write_output=False)\n",
      "    Annual report information extraction.\n",
      "    \n",
      "    This function runs the full nedextract pipleline. The pipeline is originally designed to read \n",
      "    Dutch annual report pdf files from non-profit organisation and extract relevant information.\n",
      "    It can extract information about people (task 'people') engaged in the organisation and the position they hold,\n",
      "    entities named in the file (task 'orgs'), and/or identify the sector in which the organisation is active\n",
      "    based on a provided pretrained model.\n",
      "    \n",
      "    \n",
      "    The following general steps are taken:\n",
      "    - Read in the pdf files(s) and preprocess the text.\n",
      "    - (optional) Extract mentioned people from the text and identify their position within the organisation.\n",
      "      Which of the people named in the text can be found to likely hold any of the positions of board members (directors,\n",
      "      bestuur, raad van toezicht, kascommissie, controlecommissie, edenraad), or ambassadors\n",
      "    - (optional) Extract mentioned organisations in the text. If an anbis csv file is profided, it will try to match \n",
      "      the found organisations with those in the goven file, and add additonal information from the csv file to the output.\n",
      "    - (optional) Classify the sector in which the organisation is active.\n",
      "    - The gathered information is converted into a pandas DataFrame and optionally saved to excel files.\n",
      "    \n",
      "    Args:\n",
      "        directory (str): Directory containing annual reports to be processed. \n",
      "        file (str): Path to specific pdf file to be processed.\n",
      "        url (str): URL to pdf file to be processed.\n",
      "        urlf (str): txt file containing url paths to be processed.\n",
      "        tasks (list or string): the tasks to execute. Options for tasks: 'all', 'people', 'sectors', 'orgs'\n",
      "        anbis (str), optional, only for task 'orgs': csv file for matching mentioned organisations (for task orgs)\n",
      "        model (str), only with option 'sectors': The path to the pretrained classifier file for sector prediction.\n",
      "        labels (str), only with option 'sectors': The path to the pretrained label encoding file for sector prediction.\n",
      "        vectors (str), only with option 'sectors': The path to the pretrained tf-idf vectorizer file for sector prediction.\n",
      "        write_output (bool): if true, the output will be written to an excel file\n",
      "    \n",
      "    Returns:\n",
      "        df_p, df_g, df_o: pd.DataFrames with results of the three respective tasks\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check what the run function does\n",
    "help(run_nedextract.run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-23 17:31:21 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-23 17:31:21 Working on file: /Users/lootes/Documenten/Projects/Transparency_in_the_Dutch_non-profit_sector/np-transparency/Tutorials/Data/Jaarverslag_Bedrijf.pdf\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b51474acde514fd0837576ec823e5466",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.5.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-23 17:31:21 INFO: Loading these models for language: nl (Dutch):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | alpino  |\n",
      "| ner       | conll02 |\n",
      "=======================\n",
      "\n",
      "2023-08-23 17:31:21 INFO: Using device: cpu\n",
      "2023-08-23 17:31:21 INFO: Loading: tokenize\n",
      "2023-08-23 17:31:21 INFO: Loading: ner\n",
      "2023-08-23 17:31:22 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-23 17:31:26 Finished file: /Users/lootes/Documenten/Projects/Transparency_in_the_Dutch_non-profit_sector/np-transparency/Tutorials/Data/Jaarverslag_Bedrijf.pdf\n",
      "in opdp\n",
      "The start time was:  2023-08-23 17:31:21\n",
      "The end time is:  2023-08-23 17:31:26\n"
     ]
    }
   ],
   "source": [
    "# let's extract information on people and organisations metioned in the file.\n",
    "tasks = ['people', 'orgs']\n",
    "\n",
    "# only obtain the first and third dataframe\n",
    "df_p, _, df_o = run_nedextract.run(file=file, tasks=tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracted people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out the resulting dataframe with info on mentioned people:\n",
    "df_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A.B. de Wit',\n",
       " 'Anna de Wit',\n",
       " 'Bernard Zwartjes',\n",
       " 'Cornelis Geel',\n",
       " 'D.A. Rooden',\n",
       " 'Dirkje Rooden',\n",
       " 'E. van Grijs',\n",
       " 'Eduard van Grijs',\n",
       " 'F. de Blauw',\n",
       " 'Ferdinand de Blauw',\n",
       " 'G. Roze',\n",
       " 'Gerard Roze',\n",
       " 'H. Doe',\n",
       " 'Hendrik Doe',\n",
       " 'Hendrik Groen',\n",
       " 'Isaak Paars',\n",
       " 'J. Doe',\n",
       " 'Jan van Oranje',\n",
       " 'Jane Doe',\n",
       " 'Karel',\n",
       " 'Lodewijk',\n",
       " 'Maria',\n",
       " 'Mohammed El Idrissi',\n",
       " 'Mr. H. Hendrik Groen',\n",
       " 'Nico',\n",
       " 'Otto',\n",
       " 'Pieter',\n",
       " 'Sarah',\n",
       " 'Saïda Benali',\n",
       " 'Thomas']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show lists of individual column contents\n",
    "print('the mentioned people are:')\n",
    "df_p['Persons'].to_list()[0].split(\"\\n\")[:-1]\n",
    "\n",
    "# ambassadors\n",
    "print('the ambassadors are:')\n",
    "df_p['Ambassadors'].to_list()[0].split(\"\\n\")[:-1]\n",
    "\n",
    "# board members\n",
    "print('the board members are:')\n",
    "df_p['Board_members'].to_list()[0].split(\"\\n\")[:-1]\n",
    "\n",
    "#job descriptions \n",
    "print('The are the job positions:')\n",
    "df_p['Job_description'].to_list()[0].split(\"\\n\")[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracted organisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input_file</th>\n",
       "      <th>mentioned_organization</th>\n",
       "      <th>n_mentions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jaarverslag_Bedrijf.pdf</td>\n",
       "      <td>ABCbank</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jaarverslag_Bedrijf.pdf</td>\n",
       "      <td>Bedrijf2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jaarverslag_Bedrijf.pdf</td>\n",
       "      <td>FGH</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jaarverslag_Bedrijf.pdf</td>\n",
       "      <td>Firma Accountancy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jaarverslag_Bedrijf.pdf</td>\n",
       "      <td>L9PA Foundation</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jaarverslag_Bedrijf.pdf</td>\n",
       "      <td>NL00ABCB00012345678</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Jaarverslag_Bedrijf.pdf</td>\n",
       "      <td>Stichting Non-Profit</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jaarverslag_Bedrijf.pdf</td>\n",
       "      <td>Universiteit Opleindscentrum</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Input_file        mentioned_organization n_mentions\n",
       "0  Jaarverslag_Bedrijf.pdf                       ABCbank          1\n",
       "1  Jaarverslag_Bedrijf.pdf                      Bedrijf2          1\n",
       "2  Jaarverslag_Bedrijf.pdf                           FGH          1\n",
       "3  Jaarverslag_Bedrijf.pdf             Firma Accountancy          1\n",
       "4  Jaarverslag_Bedrijf.pdf               L9PA Foundation          1\n",
       "5  Jaarverslag_Bedrijf.pdf           NL00ABCB00012345678          1\n",
       "6  Jaarverslag_Bedrijf.pdf          Stichting Non-Profit          1\n",
       "7  Jaarverslag_Bedrijf.pdf  Universiteit Opleindscentrum          1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting more data from a directory\n",
    "\n",
    "Data can also be extracted from a directory containing pdf files. In that case instead of `run_nedextract.run(file=file, tasks=tasks)`, run:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`run_nedextract.run(dir=my_Directory, tasks=tasks)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract data from a url link or multiple links\n",
    "You can also run a pdf file from a url location so that you don't have to save your data locally with:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`run_nedextract.run(url=my_url, tasks=tasks)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A number of url's to online pdf files can also be used if the links saved in a text file. Create a text file \"urls.txt\":<br>\n",
    "myurl1<br>\n",
    "myurl2<br>\n",
    "myurl3<br>\n",
    "...<br>\n",
    "<br>\n",
    "and run:<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`run_nedextract.run(urlf=urls.txt, tasks=tasks)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the output\n",
    "Run the run function with the `write_output=True` argument to save the output to excel files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying sectors\n",
    "\n",
    "In order to classify the organisation, a pretrained model has to be provided. You can pretrain your model with your own training data using the `extract_pdf.classofy_organisation.train` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function train in module nedextract.classify_organisation:\n",
      "\n",
      "train(data: pandas.core.frame.DataFrame, train_size: float, alpha: float, save: bool = False)\n",
      "    Train a MultinomialNB classifier to classify texts into the main sector categories.\n",
      "    \n",
      "    This function trains a Multinomial Naive Bayes classifier to classify text data into\n",
      "    main sector categories. It uses the given dataset ('data') containing 'text' and 'Sector'\n",
      "    columns. The 'text' column contains the textual data, and the 'Sector' column represents\n",
      "    the main sector categories that the texts belong to.\n",
      "    \n",
      "    The function performs the following steps:\n",
      "    1. Factorizes the 'Sector' column, which contains the labels, to convert categories into numerical labels.\n",
      "    2. Splits the data into training and testing sets based on the specified 'train_size'.\n",
      "    3. Applies Term Frequency-Inverse Document Frequency (TF-IDF) vectorization to the\n",
      "       training data to transform text features into numerical vectors.\n",
      "    4. Trains a Multinomial Naive Bayes classifier using the training data.\n",
      "    5. Predicts the sectors of the test data using the trained classifier.\n",
      "    6. Calculates and prints the total accuracy classification score and the confusion matrix\n",
      "       for the predicted labels.\n",
      "    7. Save the trained model to joblib files if the 'save' argument is True\n",
      "    \n",
      "    Args:\n",
      "        data (pandas.DataFrame): The dataset containing the 'text' and 'Sector' columns.\n",
      "        train_size (float): The proportion of the dataset to be used for training (0.0 to 1.0).\n",
      "        alpha (float): The additive (Laplace/Lidstone) smoothing parameter for the Naive Bayes model.\n",
      "        save (bool, optional): Whether to save the trained classifier, labels, and TF-IDF vectorizer\n",
      "                               to files in the 'Pretrained' directory. Defaults to False.\n",
      "    \n",
      "    Returns:\n",
      "        tuple: A tuple containing the trained classifier, the label encoding for sectors, and the TF-IDF vectorizer.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(classify_organisation.train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tnps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
